<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>SayuriBlog</title>
    <link>https://example.com/</link>
    <description>Recent content on SayuriBlog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>©2020 Sayuri2333.</copyright>
    <lastBuildDate>Sat, 30 Jan 2021 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://example.com/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Deep Recurrent Q Network</title>
      <link>https://example.com/post/drqn/</link>
      <pubDate>Sat, 30 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/post/drqn/</guid>
      <description>背景 在DQN的原文中，需要将游戏最近4帧的图像作为Q网络的输入。这是因为仅仅凭借1帧的画面无法判断物体运动速度和方向等的相关信息。但是在某些</description>
    </item>
    
    <item>
      <title>Analysis on Boston Housing Data</title>
      <link>https://example.com/post/analysis_on_boston_housing/</link>
      <pubDate>Thu, 21 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/post/analysis_on_boston_housing/</guid>
      <description>Introduction This study aims to find the important factors that affect the house prices in a certain area. The Boston housing price dataset is used as an example in this study. This dataset is part of the UCI Machine Learning Repository, and you can use it in Python by importing the sklearn library or in R using the MASS library. This dataset contains 13 factors such as per capita income,</description>
    </item>
    
    <item>
      <title>Wine Quality Prediction With Random Forest</title>
      <link>https://example.com/post/solve_project/</link>
      <pubDate>Thu, 21 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/post/solve_project/</guid>
      <description>Introduction For winemakers, it is very important to know how to judge the quality of wine by its chemical components. In this report, we analyze the white wine dataset, use random forest algorithm and logistic regression algorithm to build models to distinguish the quality of wine, and determine the importance of each chemical component for wine quality judgment by its weights in both algorithm. Exploratory Data Analysis First import the</description>
    </item>
    
    <item>
      <title>Dueling DQN算法</title>
      <link>https://example.com/post/duelingdqn/</link>
      <pubDate>Fri, 30 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/post/duelingdqn/</guid>
      <description>Dueling DQN的改进 Dueling DQN算法主要针对传统DQN算法对于状态价值的评估做出了改进。在传统的DQN算法中，Q网络能够预测给定\((s,a)\)的状</description>
    </item>
    
    <item>
      <title>Prioritized Experience Replay</title>
      <link>https://example.com/post/per/</link>
      <pubDate>Fri, 30 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/post/per/</guid>
      <description>PER的由来 在PER之前，像DQN（Nature 2015）以及Double DQN等Deep Q-learning方法都是通过经验回放的手段进行</description>
    </item>
    
    <item>
      <title>Double DQN算法</title>
      <link>https://example.com/post/doubledqn/</link>
      <pubDate>Thu, 29 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/post/doubledqn/</guid>
      <description>DQN 以及其改进 在原版Q-learning算法中，Q网络的优化目标为： \[ Y_{t}^{\mathrm{Q}} \equiv R_{t+1}+\gamma \max _{a} Q\left(S_{t+1}, a ; \boldsymbol{\theta}_{t}\right) \] 基于此优化目标建立均方误差损失函数，优化迭代式如下：</description>
    </item>
    
    <item>
      <title>重要性采样的问题</title>
      <link>https://example.com/post/ddpg%E7%9A%84%E9%87%8D%E8%A6%81%E6%80%A7%E9%87%87%E6%A0%B7%E9%97%AE%E9%A2%98/</link>
      <pubDate>Thu, 29 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/post/ddpg%E7%9A%84%E9%87%8D%E8%A6%81%E6%80%A7%E9%87%87%E6%A0%B7%E9%97%AE%E9%A2%98/</guid>
      <description>重要性采样在策略梯度类算法的应用 PPO算法是重要性采样在策略梯度类算法中应用的典型成果。策略梯度类算法通常以最大化期望奖励（Expected</description>
    </item>
    
    <item>
      <title>Deep Q-learning算法</title>
      <link>https://example.com/post/deep-q-learning/</link>
      <pubDate>Fri, 08 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/post/deep-q-learning/</guid>
      <description>价值函数的近似表示 之前介绍的强化学习方法使用的都是有限个状态集合\(S\)，而当遇到连续的状态时，则需要价值函数的近似表示。 价值函数的近似表</description>
    </item>
    
    <item>
      <title>Q-learning算法</title>
      <link>https://example.com/post/q-learning/</link>
      <pubDate>Fri, 08 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/post/q-learning/</guid>
      <description>Q-learning算法的引入 Q-learning算法的步骤与SARSA算法大致相同，唯一不同的地方在于SARSA算法在更新价值函数时会使用</description>
    </item>
    
    <item>
      <title>SARSA算法</title>
      <link>https://example.com/post/sarsa/</link>
      <pubDate>Fri, 08 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/post/sarsa/</guid>
      <description>SARSA算法的引入 SARSA算法不需要环境的状态转化模型，是不基于模型的强化学习问题求解方法。对于它的控制问题的求解与蒙特卡洛法相似，即通</description>
    </item>
    
  </channel>
</rss>