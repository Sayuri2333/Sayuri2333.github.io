<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on SayuriBlog</title>
    <link>https://sayuri2333.github.io/post/</link>
    <description>Recent content in Posts on SayuriBlog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>©2020 Sayuri2333.</copyright>
    <lastBuildDate>Tue, 23 Mar 2021 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://sayuri2333.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>SPSS-图表</title>
      <link>https://sayuri2333.github.io/post/spss%E4%B8%AD%E7%9A%84%E5%9B%BE/</link>
      <pubDate>Tue, 23 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://sayuri2333.github.io/post/spss%E4%B8%AD%E7%9A%84%E5%9B%BE/</guid>
      <description>常用图表 用于显示数据分布 条形图 频数/相对频数分布 饼形图 相对频数/百分比频数分布 直方图 在一个区间组集合上的频数分布 茎叶图 展示等级顺序和分布形态</description>
    </item>
    
    <item>
      <title>SPSS-数据的获得与前处理</title>
      <link>https://sayuri2333.github.io/post/spss-%E6%95%B0%E6%8D%AE%E7%9A%84%E8%8E%B7%E5%BE%97%E4%B8%8E%E5%89%8D%E5%A4%84%E7%90%86/</link>
      <pubDate>Fri, 19 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://sayuri2333.github.io/post/spss-%E6%95%B0%E6%8D%AE%E7%9A%84%E8%8E%B7%E5%BE%97%E4%B8%8E%E5%89%8D%E5%A4%84%E7%90%86/</guid>
      <description>数据的测量尺度 名义尺度（名字，身份证号） 顺序尺度（小中大，低中高） 间隔尺度（包含顺序尺度的特征+有固定单位） 比率尺度（包含间隔尺度的特征+能</description>
    </item>
    
    <item>
      <title>github使用ssh登录</title>
      <link>https://sayuri2333.github.io/post/github%E4%BD%BF%E7%94%A8ssh%E7%99%BB%E5%BD%95/</link>
      <pubDate>Tue, 09 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://sayuri2333.github.io/post/github%E4%BD%BF%E7%94%A8ssh%E7%99%BB%E5%BD%95/</guid>
      <description>配置github使用ssh公钥 git支持使用ssh以及git两种协议。如果git使用https协议，那么每次pull。push都需要输入密码</description>
    </item>
    
    <item>
      <title>GPG加密</title>
      <link>https://sayuri2333.github.io/post/gpg%E5%8A%A0%E5%AF%86/</link>
      <pubDate>Tue, 09 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://sayuri2333.github.io/post/gpg%E5%8A%A0%E5%AF%86/</guid>
      <description>对文件进行对称加密 gpg -ca himitsu.txt 对文件进行对称加密。会提示需要输入公钥，需要输入两次。执行命令后会生成himitsu.txt.asc文件。 gpg -d himitsu.txt.asc 对文</description>
    </item>
    
    <item>
      <title>QR-DQN</title>
      <link>https://sayuri2333.github.io/post/qr-dqn/</link>
      <pubDate>Fri, 05 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://sayuri2333.github.io/post/qr-dqn/</guid>
      <description>C51算法的缺陷 C51算法中虽然证明了\(\mathcal{T}\)Bellman算子在使用分布时是满足\(\gamma -contracti</description>
    </item>
    
    <item>
      <title>C51</title>
      <link>https://sayuri2333.github.io/post/c51/</link>
      <pubDate>Thu, 04 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://sayuri2333.github.io/post/c51/</guid>
      <description>经典强化学习与值分布强化学习的区别 由于状态转移的随机性，状态表示的混叠效应（编码状态时带来的信息丢失）以及函数逼近的引入（使用函数表示状态价</description>
    </item>
    
    <item>
      <title>DDPG</title>
      <link>https://sayuri2333.github.io/post/ddpg/</link>
      <pubDate>Thu, 04 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://sayuri2333.github.io/post/ddpg/</guid>
      <description>DDPG的改进 DDPG可以被视为一个对传统PG算法的改进。在Policy Gradient一文中，我们提到了REINFORCE算法，它实际上与</description>
    </item>
    
    <item>
      <title>Actor-Critic</title>
      <link>https://sayuri2333.github.io/post/actor-critic/</link>
      <pubDate>Wed, 03 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://sayuri2333.github.io/post/actor-critic/</guid>
      <description>Policy Gradient的改进 在Policy Gradient的REINFORCE算法实现中，如果某个状态下采样到的复数个动作都取得了正的奖励时，那</description>
    </item>
    
    <item>
      <title>Noisy Network</title>
      <link>https://sayuri2333.github.io/post/noisynet/</link>
      <pubDate>Tue, 02 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://sayuri2333.github.io/post/noisynet/</guid>
      <description>背景 对于DRL中面对的exploration-exploition问题，目前广泛使用以下两种方法： ε-greedy法 通常应用于DQN类算法中</description>
    </item>
    
    <item>
      <title>Policy Gradient</title>
      <link>https://sayuri2333.github.io/post/policy-gradient/</link>
      <pubDate>Tue, 02 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://sayuri2333.github.io/post/policy-gradient/</guid>
      <description>DQN类算法的不足 无法表示随机策略。 输出值（Q值）的微小改变可能会导致某一个动作被选中或者不选中，这种不连续的变化会影响算法的收敛。 无法表示</description>
    </item>
    
  </channel>
</rss>