<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>强化学习 on SayuriBlog</title>
    <link>/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/</link>
    <description>Recent content in 强化学习 on SayuriBlog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>©2020 Sayuri2333.</copyright>
    <lastBuildDate>Thu, 07 May 2020 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>蒙特卡洛法求解</title>
      <link>/post/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%B3%95/</link>
      <pubDate>Thu, 07 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%B3%95/</guid>
      <description>不基于模型的强化学习问题定义 在动态规划一文中，我们提到强化学习的两个基本问题：预测问题与控制问题。在处理上述两种问题的时候，其状态转化概率矩</description>
    </item>
    
    <item>
      <title>动态规划求解强化学习问题</title>
      <link>/post/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/</link>
      <pubDate>Wed, 06 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/</guid>
      <description>动态规划与强化学习的关系 动态规划的关键点在于：（1）问题的最优解可以由若干个小问题的最优解构成，即通过寻找子问题的最优解可以得到问题的最优解</description>
    </item>
    
    <item>
      <title>强化学习基础</title>
      <link>/post/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/</link>
      <pubDate>Wed, 06 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/</guid>
      <description>强化学习基本要素 环境状态$S$, t时刻环境的状态$S_t$是它的环境状态集中的某一个状态。 个体动作$A$， t时刻个体采取的动作$A_t$是它</description>
    </item>
    
    <item>
      <title>马尔可夫决策过程</title>
      <link>/post/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/</link>
      <pubDate>Wed, 06 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/</guid>
      <description>引入马尔可夫决策过程(MDP) 在强化学习基础介绍的强化学习要素中，状态转移概率$P_{ss&amp;rsquo;}^a$不仅与上一个状态有关，也与之</description>
    </item>
    
    <item>
      <title>强化学习入门资料</title>
      <link>/post/%E4%B9%A6%E7%9B%AE/</link>
      <pubDate>Wed, 08 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/%E4%B9%A6%E7%9B%AE/</guid>
      <description>阅读书目 PRML / 国内有非正式版翻译 Reinforcement learning: An Introduction / 有中文版 Artificial intelligence: A Modern Approach Part I-III / 有中文 翻译一般 比较general的书 Deep learning / 花书 Artificial Intelligence and Games / 有中文版 翻译质量还行</description>
    </item>
    
  </channel>
</rss>