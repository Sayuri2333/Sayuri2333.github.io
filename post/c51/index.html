<!DOCTYPE html>
<html lang="en"><meta charset="utf-8"><meta name="generator" content="Hugo 0.89.1" /><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover">
<meta name="color-scheme" content="light dark">
<meta name="supported-color-schemes" content="light dark"><title>C51&nbsp;&ndash;&nbsp;SayuriBlog</title><link rel="stylesheet" href="/css/core.min.648a6d12e2a3dde16e849ff7df9be3ae5560eafe1a16f581e9555eea238e863fe56d7308f54ae31f49106dd309b237eb.css" integrity="sha384-ZIptEuKj3eFuhJ/335vjrlVg6v4aFvWB6VVe6iOOhj/lbXMI9UrjH0kQbdMJsjfr"><body>
    <div class="base-body"><code class="html"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css"/></code>
<section id="header" class="site header">
    <div class="header wrap"><span class="header left-side"><a class="site home" href="/"><img class="site logo" src="/img/logo.jpg" alt /><span class="site name">SayuriBlog</span></a></span>
        <span class="header right-side"></span></div></section><div id="content"><section class="article header">
    <h1 class="article title">C51</h1><p class="article date">Thursday, March 4, 2021</p></section><article class="article markdown-body"><h3 id="经典强化学习与值分布强化学习的区别">经典强化学习与值分布强化学习的区别</h3>

<p>由于状态转移的随机性，状态表示的混叠效应（编码状态时带来的信息丢失）以及函数逼近的引入（使用函数表示状态价值带来的信息丢失），状态价值通常具有一定随机性，并可以用某种分布来表示。经典强化学习（DQN算法等）使用单个值的形式预测状态价值可能会忽略掉许多有效信息。因此值分布强化学习旨在拟合出状态价值的分布，从而提高预测准确性。值得一提的是，PG类算法在应用于连续动作时通常也会以某种分布作为输出。但这种情况下输出的分布为动作的概率分布，主体为动作；而值分布强化学习输出的分布为给定状态-动作对情况下其动作价值的分布，主体为价值。</p>

<h3 id="bellman算子">Bellman算子</h3>

<p>算子，即operator，接受函数输入，并输出函数。若<span  class="math">\(Q(s,a)\)</span>是一个函数，如果<span  class="math">\(s\)</span>是一个<span  class="math">\(n\)</span>维的变量，<span  class="math">\(a\)</span>是一个<span  class="math">\(m\)</span>维的变量，那么动作价值函数<span  class="math">\(Q\)</span>是一个<span  class="math">\(\mathbb{R}^n \times \mathbb{R}^m \rightarrow \mathbb{R}\)</span>的函数。我们可以引入Bellman算子<span  class="math">\(\mathcal{T}\)</span>来表示Bellman方程。对于某一个具体策略<span  class="math">\(\pi\)</span>以及状态转移矩阵<span  class="math">\(P\)</span>，我们有：</p>

<p><span  class="math">\[
\mathcal { T } ^ { \pi } Q ( x , a ) : = \mathbb { E } R ( x , a ) + \gamma \underset { P , \pi } { \mathbb { E } Q } \left( x ^ { \prime } , a ^ { \prime } \right)
\]</span></p>

<p>其中<span  class="math">\(R(s,a)\)</span>是环境的一部分，其输入输出与<span  class="math">\(Q\)</span>相同，为<span  class="math">\(\mathbb{R}^n \times \mathbb{R}^m \rightarrow \mathbb{R}\)</span>。可以看出，Bellman算子接收输入函数<span  class="math">\(Q\)</span>，并输出函数<span  class="math">\(Q'\)</span>。</p>

<p>从Bellman算子的角度来描述策略评估，其实就是在找一个函数<span  class="math">\(Q\)</span>，满足<span  class="math">\(\mathcal{T}^\pi Q = Q\)</span>，也就是在找算子的不动点（经过算子运算后函数不发生改变）。具体可以参考<a href="https://zhuanlan.zhihu.com/p/137980157">这一篇文章</a>。</p>

<p>以相同的手法我们可以定义最优Bellman算子，其用来表示Bellman最优方程：</p>

<p><span  class="math">\[
\mathcal { T } Q ( x , a ) : = \mathbb { E } R ( x , a ) + \gamma \mathbb { E } _ { P } \max _ { a ^ { \prime } \in \mathcal { A } } Q \left( x ^ { \prime } , a ^ { \prime } \right)
\]</span></p>

<p>同样的，使用最优Bellman算子做策略评估，就是在找算子<span  class="math">\( \mathcal{T}\)</span>的不动点。</p>

<p>同样由<a href="https://zhuanlan.zhihu.com/p/137980157">这篇文章</a>，可以证明算子<span  class="math">\(\mathcal{T}, \mathcal{T}^\pi\)</span>都满足<span  class="math">\(\gamma -contraction\)</span>的条件，即有：</p>

<p><span  class="math">\[
\left\| \mathcal{T}^\pi Q_1 - \mathcal{T}^\pi Q_2 \right\| _ { \infty } \leq \gamma \left\| Q_1 - Q_2 \right\| _ { \infty } \\
\]</span></p>

<p><span  class="math">\[
\left\| \mathcal{T} Q_1 - \mathcal{T} Q_2 \right\| _ { \infty } \leq \gamma \left\| Q_1 - Q_2 \right\| _ { \infty }
\]</span></p>

<p>于是根据Contraction Mapping Theorem，上述两个算子都具有唯一的不动点。即有:</p>

<p><span  class="math">\[
\begin{array} { l } \mathcal { T } ^ { \pi \infty } Q = Q ^ { \pi } \\ \mathcal { T } ^ { \infty } Q = Q ^ { * } \end{array}
\]</span></p>

<h3 id="kl散度">KL散度</h3>

<p>对于分布<span  class="math">\(p,q\)</span>，它们的KL散度定义为:</p>

<p><span  class="math">\[
\mathrm { KL } ( p \| q ) = \int p ( x ) \log \frac { p ( x ) } { q ( x ) } d x
\]</span></p>

<p>KL散度能衡量两个分布之间的差异，但是不具有对称性。其可以用于离散形式的计算，有：</p>

<p><span  class="math">\[
\mathrm { KL } ( p \| q ) = \sum _ { i = 1 } ^ { N } p \left( x _ { i } \right) \log \frac { p \left( x _ { i } \right) } { q \left( x _ { i } \right) } = \sum _ { i = 1 } ^ { N } p \left( x _ { i } \right) \left[ \log p \left( x _ { i } \right) - \log q \left( x _ { i } \right) \right]
\]</span></p>

<h3 id="distributional-dqn">Distributional DQN</h3>

<p>Distributional DQN将传统DQN中的value function换成了value distribution。原来的DQN中的值函数为<span  class="math">\(Q(s,a)\)</span>，它接收一个状态动作对<span  class="math">\(s,a\)</span>，并输出实数格式的动作价值<span  class="math">\(Q\)</span>。</p>

<p>与其相对，Distributional DQN接收一个状态动作对<span  class="math">\(x,a\)</span>，并输出一个值分布<span  class="math">\(Z(x,a)=P(v | x,a)\)</span>，这个分布描绘了状态动作对<span  class="math">\(x,a\)</span>所有可能的价值<span  class="math">\(v\)</span>的范围以及可能性。易得，<span  class="math">\(Q(x,a) = \mathbb{E}[Z(x,a)]\)</span>。</p>

<p>针对值分布，可以定义状态转移算子：</p>

<p><span  class="math">\[
\begin{aligned} P ^ { \pi } Z ( x , a ) & : = Z \left( X ^ { \prime } , A ^ { \prime } \right) \\ X ^ { \prime } & \sim P ( \cdot \mid x , a ) , A ^ { \prime } \sim \pi \left( \cdot \mid X ^ { \prime } \right) \end{aligned}
\]</span></p>

<p>这个算子是<span  class="math">\(\mathcal { Z } \rightarrow \mathcal { Z }\)</span>，也就是接收一个分布，并输出另一个分布。可以看出，算子接收当前状态动作对<span  class="math">\(x,a\)</span>生成的值分布<span  class="math">\(Z(x,a)\)</span>，根据状态转移矩阵<span  class="math">\(P\)</span>以及当前策略<span  class="math">\(\pi\)</span>生成下一时刻状态动作对<span  class="math">\(x',a'\)</span>生成的值分布<span  class="math">\(Z(x',a')\)</span>。</p>

<p>在值分布情况下的Bellman算子就可以被定义为：</p>

<p><span  class="math">\[
\mathcal { T } ^ { \pi } Z ( x , a ) : \stackrel { D } { = } R ( x , a ) + \gamma P ^ { \pi } Z ( x , a )
\]</span></p>

<p>与状态转移算子<span  class="math">\(P^\pi\)</span>相同，值分布下的Bellman算子同样也是<span  class="math">\(\mathcal{Z} \rightarrow \mathcal{Z}\)</span>。可视化后的情况如下图：</p>

<p><figure><img src="/image/Bellman_operator.png" alt="png"></figure></p>

<p>在DQN中，我们计算出一个<span  class="math">\(r + \gamma \underset{a^*} \max Q(x', a^*)\)</span>，并使当前<span  class="math">\(Q(x,a)\)</span>尽量靠近这个值。相对应的，我们可以在Distributional DQN中定义最优Bellman算子<span  class="math">\(\mathcal{T} Z\)</span>，其满足：</p>

<p><span  class="math">\[
\mathcal { T } Z = \mathcal { T } ^ { \pi } Z \text { for } \pi \in \mathcal { G } _ { Z } \\ \mathcal { G } _ { Z } : = \left\{ \pi : \sum _ { a } \pi ( a \mid x ) \mathbb { E } Z ( x , a ) = \max _ { a ^ { \prime } \in \mathcal { A } } \mathbb { E } Z \left( x , a ^ { \prime } \right) \right\}
\]</span></p>

<p><span  class="math">\(\mathcal { G } _ { Z }\)</span>看起来很复杂，但实际上指的是令策略<span  class="math">\(\pi\)</span>取最优策略。因此，在Distributional DQN中，我们需要让当前值分布<span  class="math">\(Z(x,a)\)</span>尽可能的靠近<span  class="math">\(\mathcal{T} Z(x,a)\)</span>这个分布。</p>

<h3 id="c51定义">C51定义</h3>

<p>由于<span  class="math">\(Z(x,a)\)</span>分布并不一定符合某种特殊的预设模式，因此C51方法放弃使用高斯分布等参数化方式表示<span  class="math">\(Z(x,a)\)</span>，而是使用了51个等间距的atoms描绘一个分布。实际上其与描绘分布的直方图差距不大，但是直方图更注重区间，而C51算法使用的comb form的方法更注重&quot;点&quot;。当然这个分布肯定是近似的结果，点的范围和个数取决于应用情况。实际上，假设分布<span  class="math">\(Z(x,a)\)</span>的上界为<span  class="math">\(V_{MAX}\)</span>，下界<span  class="math">\(V_{MIN}\)</span>，将最大值和最小值之间的区间均匀化为<span  class="math">\(N\)</span>个点，则每个点<span  class="math">\(\mathcal{z}_i\)</span>有：</p>

<p><span  class="math">\[
\left\{ z _ { i } = V _ { \min } + i \Delta z : 0 \leq i < N , \Delta z : = \frac { V _ { M A X } - V _ { M I N } } { N - 1 } \right\}
\]</span></p>

<p>例如，当<span  class="math">\(N=7\)</span>时，一共有7个atoms，其分布可能为：</p>

<p><figure><img src="/image/C51.png" alt="png"></figure></p>

<p>现在我们来考虑C51的网络架构。在DQN中，网络的输入为<span  class="math">\(s\)</span>，输出为<span  class="math">\(|\mathcal{A}|\)</span>维的一个向量<span  class="math">\((Q(s,a_1), Q(s,a_2),...,Q(s,a_m))\)</span>。向量的每一个元素代表对应动作状态对<span  class="math">\(s,a\)</span>的预测<span  class="math">\(Q\)</span>值。而在C51算法中，输出变成了一个矩阵。矩阵的行数为<span  class="math">\(|\mathcal{A}|\)</span>，每一行代表给定<span  class="math">\(s,a\)</span>的值分布。矩阵的列数为<span  class="math">\(N\)</span>，每一列代表值分布在给定atom上的概率。若atoms集合为<span  class="math">\(\left\{ z _ { 0 } , z _ { 1 } , \cdots , z _ { N - 1 } \right\}\)</span>，C51的输出应该为<span  class="math">\((\left\{ p _ { 0 } ^ { a_1 } , p _ { 1 } ^ { a_1 } , \cdots , p _ { N - 1 } ^ { a_1 } \right\}, \left\{ p _ { 0 } ^ { a_2 } , p _ { 1 } ^ { a_2 } , \cdots , p _ { N - 1 } ^ { a_2 } \right\} \cdots , \left\{ p _ { 0 } ^ { a_m } , p _ { 1 } ^ { a_m } , \cdots , p _ { N - 1 } ^ { a_m } \right\})\)</span>。</p>

<p>为了保证神经网络输出的矩阵的每一行构成一个离散的分布，可以对神经网络的输出进行softmax操作。具体为：</p>

<p><span  class="math">\[
Z _ { \theta } ( x , a ) = z _ { i } \quad w . p . p _ { i } ( x , a ) : = \frac { e ^ { \theta _ { i } ( x , a ) } } { \sum _ { j } e ^ { \theta _ { j } ( x , a ) } }
\]</span></p>

<h3 id="c51损失函数">C51损失函数</h3>

<p>网络结构定义完成后，我们需要设置损失函数，从而完成训练过程。在DQN中，由于网络输出为一个实数，因此我们可以使用均方误差作为损失函数。但是C51算法输出为一个分布，因此我们需要找到一个衡量分布之间距离的方法。通常我们使用Wasserstein Metric作为衡量分布距离的方法（具体解释看<a href="https://zhuanlan.zhihu.com/p/58506295">这篇文章</a>，其实也看不太懂呜呜）。使用Wasserstein Metric可以保证Bellman算子在输出分布的情况下也满足<span  class="math">\(\gamma - contraction\)</span>的条件。但是，对于Q-learning实际用到的最优Bellman算子则没有这样的理论保证。而且使用SGD方法训练时是没有办法保持Wasserstein Metric的。因此，C51算法使用了KL散度启发式的衡量两个分布的距离。</p>

<h3 id="投影bellman更新">投影Bellman更新</h3>

<p>使用KL散度的离散形式计算可以很容易的算出两个分布之间的距离。但是在实际运算中还会产生一个问题。我们可以通过模拟整个过程找出问题。</p>

<p>首先我们从Buffer中采样一个<span  class="math">\((s,a,r,s')\)</span>，根据q-learning函数使用的最优Bellman算子，有：</p>

<p><span  class="math">\[
\mathcal { T } Z ( x , a ) : \stackrel { D } { = } R ( x , a ) + \gamma P Z ( x , a )
\]</span></p>

<p>因此为了改善<span  class="math">\(Z(x,a)\)</span>，我们需要计算<span  class="math">\(R(x,a) + \gamma Z(x',a^*)\)</span>。在DQN中，<span  class="math">\(a^*\)</span>的选择是根据<span  class="math">\(a ^ { * } \leftarrow \arg \max _ { a } Q \left( x' , a \right)\)</span>标准的。在C51中我们沿用这个标准，并通过<span  class="math">\(Q(x,a) = \mathbb{E}[Z(x,a)]\)</span>来计算<span  class="math">\(Q(x,a)\)</span>。具体有：</p>

<p><span  class="math">\[
Q \left( s _ { t + 1 } , a \right) : = \sum _ { i } z _ { i } p _ { i } \left( s _ { t + 1 } , a \right)
\]</span></p>

<p>根据上述标准，我们可以从target network中获得<span  class="math">\(Z(x',a^*)\)</span>的结果，是一个<span  class="math">\(N\)</span>维的向量，我们设其为<span  class="math">\(p'\)</span>。那么<span  class="math">\(R(x,a) + \gamma Z(x',a^*)\)</span>分布就可以表示为:</p>

<blockquote>
<p>有<span  class="math">\(p'_{0}\)</span>的概率取<span  class="math">\(R + \gamma z_0\)</span></p>

<p>有<span  class="math">\(p'_{1}\)</span>的概率取<span  class="math">\(R + \gamma z_1\)</span></p>

<p>......</p>

<p>有<span  class="math">\(p'_{N-1}\)</span>的概率取<span  class="math">\(R + \gamma z_{N-1}\)</span></p>
</blockquote>

<p>但我们检查<span  class="math">\(Z(x,a)\)</span>可以发现，其可以表示为：</p>

<blockquote>
<p>有<span  class="math">\(p'_{0}\)</span>的概率取<span  class="math">\( z_0 \)</span></p>

<p>有<span  class="math">\(p'_{1}\)</span>的概率取<span  class="math">\(z_1\)</span></p>

<p>......</p>

<p>有<span  class="math">\(p'_{N-1}\)</span>的概率取<span  class="math">\(z_{N-1}\)</span></p>
</blockquote>

<p>可以发现，<span  class="math">\(Z(x,a)\)</span>与<span  class="math">\(R(x,a) + \gamma Z(x',a^*)\)</span>的atoms没有对齐。C51的解决方法是，将<span  class="math">\(R + \gamma z_k\)</span>的概率分摊到<span  class="math">\(z_k\)</span>和<span  class="math">\(z_{k+1}\)</span>上。具体的分摊比例按照<span  class="math">\(R + \gamma z_k\)</span>到<span  class="math">\(z_k\)</span>与<span  class="math">\(z_{k+1}\)</span>的距离的反比即可。</p>

<p>以<a href="https://zhuanlan.zhihu.com/p/65364484">这篇文章</a>中的例子，令<span  class="math">\(\hat { \mathcal { T } } z _ { 0 } = R + \gamma z_0\)</span>对应的概率为<span  class="math">\(p_0(x',a')\)</span>，将其投影到相邻的支点<span  class="math">\(z_0,z_1\)</span>上，如图：</p>

<p><figure><img src="/image/Bellman_projection.png" alt=""></figure></p>

<p>则<span  class="math">\(z_0\)</span>分得的概率的大小为：</p>

<p><span  class="math">\[
[1 - \frac { \hat { \mathcal { T } } z _ { 0 } - z _ { 0 } } { z_1 - z_0 }]p _ { 0 } \left( x ^ { \prime } , a ^ { \prime } \right)
\]</span></p>

<p>经过上述分配，我们可以得到一个新的分布<span  class="math">\(\Phi  { \mathcal { T } } Z  ( x , a )\)</span>，损失函数可得为：</p>

<p><span  class="math">\[
D_{KL}(\Phi  { \mathcal { T } } Z  ( x , a ) || Z(x,a))
\]</span></p>

<p>C51具体算法流程如下：</p>

<p><figure><img src="/image/C51_algo.png" alt=""></figure></p>
</article><section class="article labels"><a class="category" href=/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/>强化学习</a></section><section class="article navigation"><p><a class="link" href="/post/qr-dqn/"><span class="li">&larr;</span>QR-DQN</a></p><p><a class="link" href="/post/ddpg/"><span class="li">&rarr;</span>DDPG</a class="link">
    </p></section></div><code class="html"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.js"integrity="sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/contrib/auto-render.min.js"integrity="sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe"crossorigin="anonymous"onload="renderMathInElement(document.body,{delimiters: [{left: '$$', right: '$$', display: true},{left: '$', right: '$', display: false}]});"></script>
</code>
<section id="footer" class="footer"><div class="footer-wrap">
    <p class="copyright">©2020 <a href="https://github.com/Sayuri2333" target="_blank">Sayuri2333</a>.</p>
    <p class="powerby"><span>Powered by </span><a href="https://gohugo.io" 
        target="_blank">Hugo</a><span> and the </span><a href="https://themes.gohugo.io/hugo-notepadium/" 
        target="_blank">Notepadium</a></p>
</div>
</section><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/&#43;DiW/UqRcLbRjq" crossorigin="anonymous"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l&#43;B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd&#43;qj&#43;o24G5ZU2zJz" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
            onload="renderMathInElement(document.body);"></script></div>
</body>

</html>