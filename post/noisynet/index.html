<!DOCTYPE html>
<html lang="en"><meta charset="utf-8"><meta name="generator" content="Hugo 0.89.1" /><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover">
<meta name="color-scheme" content="light dark">
<meta name="supported-color-schemes" content="light dark"><title>Noisy Network&nbsp;&ndash;&nbsp;SayuriBlog</title><link rel="stylesheet" href="/css/core.min.648a6d12e2a3dde16e849ff7df9be3ae5560eafe1a16f581e9555eea238e863fe56d7308f54ae31f49106dd309b237eb.css" integrity="sha384-ZIptEuKj3eFuhJ/335vjrlVg6v4aFvWB6VVe6iOOhj/lbXMI9UrjH0kQbdMJsjfr"><body>
    <div class="base-body"><code class="html"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css"/></code>
<section id="header" class="site header">
    <div class="header wrap"><span class="header left-side"><a class="site home" href="/"><img class="site logo" src="/img/logo.jpg" alt /><span class="site name">SayuriBlog</span></a></span>
        <span class="header right-side"></span></div></section><div id="content"><section class="article header">
    <h1 class="article title">Noisy Network</h1><p class="article date">Tuesday, March 2, 2021</p></section><article class="article markdown-body"><h3 id="背景">背景</h3>

<p>对于DRL中面对的exploration-exploition问题，目前广泛使用以下两种方法：</p>

<ul>
<li><strong>ε-greedy法</strong> 通常应用于DQN类算法中，使agent以<span  class="math">\(ε\)</span>的概率采取随机行动，通常会在训练开始时设置<span  class="math">\(\epsilon\)</span>为1，然后慢慢衰减</li>
<li><strong>熵正则化(entropy regularisation)</strong> 通常用于策略梯度算法中，通过将策略<span  class="math">\(\pi\)</span>的熵加入到损失函数中，算法能够生成更为均匀平滑的策略</li>
</ul>

<h3 id="noisynet">NoisyNet</h3>

<p>相比较上述两种方法将exploration分别使用启发式搜索以及损失函数的方式引入算法，NoisyNet算法通过将高斯噪声添加到网络中最后的完全连接层来实现exploration的引入。</p>

<p>相比于普通的神经网络，NoisyNet的权重和偏置都会受到噪音的影响。设其数学表示为<span  class="math">\(y=f_{\theta}(x)\)</span>，其中<span  class="math">\(\theta\)</span>为受噪声影响的参数，则<span  class="math">\(\theta\)</span>可以被定义为：</p>

<p><span  class="math">\[
\theta \stackrel{\text { def }}{=} \mu+\Sigma \odot \varepsilon
\]</span></p>

<p>其中<span  class="math">\(\zeta \stackrel{\text { def }}{=}(\mu, \Sigma)\)</span>为可学习的向量，<span  class="math">\(\varepsilon\)</span>为均值为0的高斯噪声，<span  class="math">\(\Sigma\)</span>为噪声的权重，<span  class="math">\(\odot\)</span>表示点乘。NoisyNet的损失函数可以表示为：</p>

<p><span  class="math">\[
\bar{L}(\zeta) \stackrel{\text { def }}{=} \mathbb{E}[L(\theta)]
\]</span></p>

<p>也就是说，在优化的时候，只对<span  class="math">\(\zeta\)</span>中的参数计算梯度，而不对噪声进行优化；但是在计算损失函数的时候，则考虑到噪声的影响，使用<span  class="math">\(\theta\)</span>作为参数。</p>

<p>举个例子，考虑线性模型<span  class="math">\(y=w x+b\)</span>，未经过噪声扰动时，其参数为<span  class="math">\(w\)</span>，<span  class="math">\(b\)</span>；经过噪声扰动后，式子变成：</p>

<p><span  class="math">\[
y \stackrel{\text { def }}{=}\left(\mu^{w}+\sigma^{w} \odot \varepsilon^{w}\right) x+\mu^{b}+\sigma^{b} \odot \varepsilon^{b}
\]</span></p>

<p>其中<span  class="math">\(\mu^{w}\)</span>,<span  class="math">\(\sigma^{w}\)</span>,<span  class="math">\(\mu^{b}\)</span>以及<span  class="math">\(\sigma^{b}\)</span>是可以调整的，而<span  class="math">\(\varepsilon^{w}\)</span>以及<span  class="math">\(\varepsilon^{b}\)</span>是不可以调整的。</p>

<h3 id="引入噪声的方法">引入噪声的方法</h3>

<p><a href="https://arxiv.org/pdf/1706.10295v1.pdf"> Noisy Networks for Exploration </a>一文中提供了。两种引入噪声的方法。</p>

<ul>
<li><p><strong>Independent Gaussian noise</strong> 指的是给每一个权重都添加一个独立的噪声，并且具有模型自己学习的<span  class="math">\(\mu\)</span>和<span  class="math">\(\sigma\)</span>。假设一个具有p个神经元输入，q个神经元输出的全连接层，在这种情况下，需要的随机噪声变量个数为(pq+q)个。</p></li>

<li><p><strong>Factorised Gaussian noise</strong> 指的是分配给每一个神经元一个独立的高斯噪声，每个神经元具有独立的<span  class="math">\(\mu\)</span>和<span  class="math">\(\sigma\)</span>。具体到每一个权重，权重<span  class="math">\(w_{i j}\)</span>的噪声为</p></li>
</ul>

<p><span  class="math">\[
  \varepsilon_{i, j}^{w}=f\left(\varepsilon_{i}\right) f\left(\varepsilon_{j}\right)
  \]</span></p>

<p>偏置<span  class="math">\(b_{j}\)</span>的噪声为</p>

<p><span  class="math">\[
  \varepsilon_{j}^{b}=f\left(\varepsilon_{j}\right)
  \]</span></p>

<p>其中<span  class="math">\(f\)</span>可以使用<span  class="math">\(f(x)=\operatorname{sgn}(x) \sqrt{|x|}\)</span></p>

<h3 id="计算">计算</h3>

<p>根据损失函数，可以定义梯度为</p>

<p><span  class="math">\[
\nabla \bar{L}(\zeta)=\nabla \mathbb{E}[L(\theta)]=\mathbb{E}\left[\nabla_{\mu, \Sigma} L(\mu+\Sigma \odot \varepsilon)\right]
\]</span></p>

<p>使用蒙特卡洛法估计有</p>

<p><span  class="math">\[
\nabla \bar{L}(\zeta) \approx \nabla_{\mu, \Sigma} L(\mu+\Sigma \odot \xi)
\]</span></p>

<p>在DQN中存在Online network以及Target Network，其参数分别为<span  class="math">\(\theta\)</span>以及<span  class="math">\(\theta'\)</span>。当使用Noisy Network时，就变成了Online Network<span  class="math">\(Q(s, a, \varepsilon ; \zeta)\)</span>以及Target Network<span  class="math">\(Q\left(s, a, \varepsilon^{\prime} ; \zeta^{-}\right)\)</span>。使用蒙特卡洛法的损失函数为</p>

<p><span  class="math">\[
\bar{L}(\zeta)=\mathbb{E}\left[\mathbb{E}_{(s, a, r, y) \sim D}\left[r+\gamma \max _{b \in A} Q\left(s', b, \varepsilon^{\prime} ; \zeta^{-}\right)-Q(s, a, \varepsilon ; \zeta)\right]^{2}\right]
\]</span></p>

<p>其中<span  class="math">\(\varepsilon\)</span>以及<span  class="math">\(\varepsilon'\)</span>为分别采样的噪声。作者建议在DQN中，每一个新的batch重新采样一次噪声。</p>

<p>具体流程如下：</p>

<p><figure><img src="/image/NoisyDQN.png" alt="png"></figure></p>

<p>Noisy Network也能应用在A3C中，具体参考<a href="https://arxiv.org/pdf/1706.10295v1.pdf"> Noisy Networks for Exploration </a>。</p>
</article><section class="article labels"><a class="category" href=/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/>强化学习</a></section><section class="article navigation"><p><a class="link" href="/post/actor-critic/"><span class="li">&larr;</span>Actor-Critic</a></p><p><a class="link" href="/post/policy-gradient/"><span class="li">&rarr;</span>Policy Gradient</a class="link">
    </p></section></div><code class="html"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.js"integrity="sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/contrib/auto-render.min.js"integrity="sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe"crossorigin="anonymous"onload="renderMathInElement(document.body,{delimiters: [{left: '$$', right: '$$', display: true},{left: '$', right: '$', display: false}]});"></script>
</code>
<section id="footer" class="footer"><div class="footer-wrap">
    <p class="copyright">©2020 <a href="https://github.com/Sayuri2333" target="_blank">Sayuri2333</a>.</p>
    <p class="powerby"><span>Powered by </span><a href="https://gohugo.io" 
        target="_blank">Hugo</a><span> and the </span><a href="https://themes.gohugo.io/hugo-notepadium/" 
        target="_blank">Notepadium</a></p>
</div>
</section><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/&#43;DiW/UqRcLbRjq" crossorigin="anonymous"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l&#43;B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd&#43;qj&#43;o24G5ZU2zJz" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
            onload="renderMathInElement(document.body);"></script></div>
</body>

</html>